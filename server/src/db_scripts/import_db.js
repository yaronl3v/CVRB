#!/usr/bin/env node

/**
 * DB Importer
 *
 * Clears the `solutions` and `worlds` tables and loads records from JSON dump
 * files generated by `export_db.js`.
 *
 * IMPORTANT: This script **deletes** the current table contents. Make sure you
 * have the correct backup before running.
 *
 * Usage: node src/cvrb_scripts/import_db.js [inputDir]
 *   inputDir (optional) – relative directory name containing `worlds.json` and
 *                          `solutions.json` (default: db_exports)
 */

import fs from 'fs-extra';
import path from 'path';
import { fileURLToPath } from 'url';
import dotenv from 'dotenv';

import db from '../db.js';
import World from '../models/World.js';
import Solution from '../models/Solution.js';

// -----------------------------------------------------------------------------
// Environment
// -----------------------------------------------------------------------------
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

dotenv.config({ path: path.join(__dirname, '..', '..', '.env') });

// -----------------------------------------------------------------------------
// Helper class
// -----------------------------------------------------------------------------
class DBImporter {
  constructor(dirName = 'db_exports') {
    this.inputDir = path.join(__dirname, '..', dirName);
  }

  async run() {
    const connected = await db.testConnection();
    if (!connected) {
      console.error('Exiting: could not establish DB connection');
      process.exit(1);
    }

    const sequelize = db.getSequelize();
    const worldsPath = path.join(this.inputDir, 'worlds.json');
    const solutionsPath = path.join(this.inputDir, 'solutions.json');

    const [worldsData, solutionsData] = await Promise.all([
      fs.readJson(worldsPath),
      fs.readJson(solutionsPath)
    ]);

    const transaction = await sequelize.transaction();

    try {
      // Delete existing data (solutions first due to FK)
      await Solution.destroy({ where: {}, transaction });
      await World.destroy({ where: {}, transaction, cascade: true });

      // Bulk insert from dumps, include IDs for FK integrity
      await World.bulkCreate(worldsData, { transaction });
      await Solution.bulkCreate(solutionsData, { transaction });

      // Sync sequences with max(id)
      await sequelize.query(
        "SELECT setval(pg_get_serial_sequence('worlds', 'id'), (SELECT COALESCE(MAX(id), 1) FROM worlds));",
        { transaction }
      );
      await sequelize.query(
        "SELECT setval(pg_get_serial_sequence('solutions', 'id'), (SELECT COALESCE(MAX(id), 1) FROM solutions));",
        { transaction }
      );

      await transaction.commit();
      console.log('✅ Import completed successfully.');
    } catch (err) {
      await transaction.rollback();
      console.error('Import failed, changes rolled back:', err);
      process.exit(1);
    } finally {
      await db.close();
    }
  }
}

// -----------------------------------------------------------------------------
// Main
// -----------------------------------------------------------------------------
async function main() {
  const [, , customDir] = process.argv;
  const importer = new DBImporter(customDir);
  try {
    await importer.run();
  } catch (err) {
    console.error('Import failed:', err);
    process.exit(1);
  }
}

main();
